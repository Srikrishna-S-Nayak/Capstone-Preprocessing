{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T23:22:30.784734Z",
     "start_time": "2024-04-17T23:22:25.000113Z"
    }
   },
   "source": [
    "import cv2\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('./data/D19_20230511115642.mp4')\n",
    "\n",
    "# Create a background subtractor object\n",
    "back_sub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    back_sub_mask = back_sub.apply(frame)\n",
    "\n",
    "    # Apply further preprocessing steps (e.g., erosion, dilation)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    back_sub_mask = cv2.morphologyEx(back_sub_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', back_sub_mask)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f365a434c175c49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T10:42:04.943466Z",
     "start_time": "2024-04-17T10:40:06.089244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Resized\n",
    "import cv2\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('./data/D19_20230511115642.mp4')\n",
    "\n",
    "# Create a background subtractor object\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "\n",
    "# Initialize the first frame as the background\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Failed to read the video file.\")\n",
    "    exit()\n",
    "\n",
    "fgbg.apply(frame)  # Apply the first frame to initialize the background model\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Apply further preprocessing steps (e.g., erosion, dilation)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Resize the windows for better display\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    fgmask = cv2.resize(fgmask, (640, 360))\n",
    "\n",
    "    # Display the processed frame and foreground mask\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.moveWindow('Frame', 100, 100)  # Move the window position\n",
    "    cv2.imshow('Foreground Mask', fgmask)\n",
    "    cv2.moveWindow('Foreground Mask', 800, 100)  # Move the window position\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "2632eca90d3a1192",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T23:37:07.483527Z",
     "start_time": "2024-04-17T23:37:00.491947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Skipping first 60 frames and background sub\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('./data/D19_20230511115642.mp4')\n",
    "\n",
    "# Initialize background subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "\n",
    "# Initialize object detector and tracker\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=64, detectShadows=True)\n",
    "tracker = cv2.legacy.MultiTracker.create()\n",
    "\n",
    "# Skip the first 60 frames for better background modeling\n",
    "for _ in range(60):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read the video file.\")\n",
    "        exit()\n",
    "    fgbg.apply(frame, learningRate=0.001)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fgmask = fgbg.apply(frame, learningRate=0.001)\n",
    "\n",
    "    # Apply object detection\n",
    "    obj_mask = object_detector.apply(frame)\n",
    "    _, obj_mask = cv2.threshold(obj_mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    obj_contours, _ = cv2.findContours(obj_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Update object tracker\n",
    "    boxes = []\n",
    "    for contour in obj_contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:  # Ignore small contours\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            boxes.append((x, y, w, h))\n",
    "    tracker.update(frame, boxes)\n",
    "\n",
    "    # Draw bounding boxes for tracked objects\n",
    "    for box in tracker.getObjects():\n",
    "        x, y, w, h = [int(v) for v in box]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Apply further preprocessing steps (e.g., erosion, dilation)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Colorize the foreground mask\n",
    "    fgmask = cv2.applyColorMap(fgmask, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Resize the windows for better display\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    fgmask = cv2.resize(fgmask, (640, 360))\n",
    "\n",
    "    # Display the processed frame and foreground mask\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.moveWindow('Frame', 100, 100)\n",
    "    cv2.imshow('Foreground Mask', fgmask)\n",
    "    cv2.moveWindow('Foreground Mask', 800, 100)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "5887f9fdb71115a9",
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'update'\n> Overload resolution failed:\n>  - legacy_MultiTracker.update() takes at most 1 argument (2 given)\n>  - legacy_MultiTracker.update() takes at most 1 argument (2 given)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 45\u001B[0m\n\u001B[0;32m     43\u001B[0m         x, y, w, h \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mboundingRect(contour)\n\u001B[0;32m     44\u001B[0m         boxes\u001B[38;5;241m.\u001B[39mappend((x, y, w, h))\n\u001B[1;32m---> 45\u001B[0m \u001B[43mtracker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mboxes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# Draw bounding boxes for tracked objects\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m box \u001B[38;5;129;01min\u001B[39;00m tracker\u001B[38;5;241m.\u001B[39mgetObjects():\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'update'\n> Overload resolution failed:\n>  - legacy_MultiTracker.update() takes at most 1 argument (2 given)\n>  - legacy_MultiTracker.update() takes at most 1 argument (2 given)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T23:37:56.908617Z",
     "start_time": "2024-04-17T23:37:47.843131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('./data/D19_20230511115642.mp4')\n",
    "\n",
    "# Initialize background subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "\n",
    "# Initialize object detector\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=64, detectShadows=True)\n",
    "\n",
    "# Initialize dictionary to store trackers\n",
    "trackers = {}\n",
    "\n",
    "# Skip the first 60 frames for better background modeling\n",
    "for _ in range(60):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read the video file.\")\n",
    "        exit()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fgmask = fgbg.apply(frame, learningRate=0.001)\n",
    "\n",
    "    # Apply object detection\n",
    "    obj_mask = object_detector.apply(frame)\n",
    "    _, obj_mask = cv2.threshold(obj_mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    obj_contours, _ = cv2.findContours(obj_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Update object trackers\n",
    "    for contour in obj_contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:  # Ignore small contours\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # Create a new tracker if not already created\n",
    "            if (x, y, w, h) not in trackers:\n",
    "                trackers[(x, y, w, h)] = cv2.legacy.TrackerCSRT_create()\n",
    "                trackers[(x, y, w, h)].init(frame, (x, y, w, h))\n",
    "            else:\n",
    "                # Update existing tracker\n",
    "                trackers[(x, y, w, h)].update(frame)\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Apply further preprocessing steps (e.g., erosion, dilation)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Colorize the foreground mask\n",
    "    fgmask = cv2.applyColorMap(fgmask, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Resize the windows for better display\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    fgmask = cv2.resize(fgmask, (640, 360))\n",
    "\n",
    "    # Display the processed frame and foreground mask\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.moveWindow('Frame', 100, 100)\n",
    "    cv2.imshow('Foreground Mask', fgmask)\n",
    "    cv2.moveWindow('Foreground Mask', 800, 100)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "fb6e3db5b93851b7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14c4a564771a981"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
